---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

> You can also find the articles on my [[<span style ="color:#800080">*Google Scholar*</span>](https://scholar.google.com/citations?user=GBaSF7MAAAAJ&hl=en)  \|  [<span style ="color:#800080">*ResearchGate*</span>](https://www.researchgate.net/profile/G-Shahariar)  \|  [<span style ="color:#800080">*ORCID*</span>](https://orcid.org/0000-0001-9757-7663)  \|  [<span style ="color:#800080">*Scopus*</span>](https://www.scopus.com/authid/detail.uri?authorId=57844100100)  \|  [<span style ="color:#800080">*Semantic Scholar*</span>](https://www.semanticscholar.org/author/G.-M.-Shahariar/100649170)] profile.

## 2023
---------
üìå [<span style="color:red">**Interpretable Multi Labeled Bengali Toxic Comments Classification using Deep Learning**</span>](https://ieeexplore.ieee.org/document/10101588) 
(<span style="color:#6E2C00"><strong>Best Paper Award</strong></span> üèÜ)
<span style="color:black"><font size="3"><strong>Authors</strong>: Tanveer Ahmed Belal, <strong style="color:green">G. M. Shahariar</strong>, and Md. Hasanul Kabir </font></span><br>
<span style="color:black"><font size="3"><strong>Conference:</strong><em> 3rd International Conference on Electrical, Computer and Communication Engineering</em></font> ([ECCE 2023](https://webs.cuet.ac.bd/ecce/))</span><br>
[[<span style ="color:Blue"><font size="3"><strong>PDF</strong></font></span>](https://www.researchgate.net/publication/369924719_Interpretable_Multi_Labeled_Bengali_Toxic_Comments_Classification_using_Deep_Learning)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Code & Dataset</strong></font></span>](https://github.com/deepu099cse/Multi-Labeled-Bengali-Toxic-Comments-Classification)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Presentation</strong></font></span>](https://shahariar-shibli.github.io/files/ECCE2023/ECCE-Toxic-Comments-Presentation.pptx) \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/ECCE2023/Toxic-Comment.bib)] \| [<a href="#" onclick="$('#ecce2023_summary').toggle();return false;">Click to read a short summary!</a>]
<div id="ecce2023_summary" class="summary" style="display:none;">
	<p style="text-align:justify; color:black;"> 
		<font size="3">
			This paper presents a deep learning-based pipeline for categorizing Bengali toxic comments, 
			in which at first a binary classification model is used to determine whether a comment is toxic or not, and then a multi-label classifier is employed to 
			determine which toxicity type the comment belongs to.
		</font>
	</p>
</div>

üìå [<span style="color:red">**Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks**</span>](https://www.researchgate.net/publication/369855297_Bengali_Fake_Review_Detection_using_Semi-supervised_Generative_Adversarial_Networks)
<details>
<summary><font size="3">Click to read a short summary!</font></summary>
<span style="text-align:justify; color:black; display:block;">
<font size="3"> 
In this paper, we demonstrated that the proposed semi-supervised
GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake 
reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) 
achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models - BanglaBERT generator, 
Bangla BERT Base and Bangla-Electra by almost 3%, 4% and 10% respectively in terms of accuracy.
</font>
</span>
</details>
<span style="color:black"><font size="3"><strong>Authors</strong>: Md. Tanvir Rouf Shawon, <strong style="color:green">G. M. Shahariar</strong>, Faisal Muhammad Shah, Mohammad Shafiul Alam, and Md. Shahriar Mahbub</font></span><br>
<span style="color:black"><font size="3"><strong>Conference:</strong><em> 5th International Conference on Natural Language Processing</em></font> ([ICNLP 2023](http://www.icnlp.net/index.html))</span><br>
[[<span style ="color:#6E2C00"><font size="3"><strong>arXiv</strong></font></span>](https://arxiv.org/abs/2304.02739)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Presentation</strong></font></span>](https://shahariar-shibli.github.io/files/ICNLP2023/BFRD-Final.pdf)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/ICNLP2023/Bangla-Fake.bib)]
     
üìå [<span style="color:red">**Effectiveness of Transformer Models on IoT Security Detection in StackOverflow Discussions**</span>](https://link.springer.com/chapter/10.1007/978-981-19-7528-8_10)
<details>
<summary><font size="3">Click to read a short summary!</font></summary>
<span style="text-align:justify; color:black; display:block;"> 
<font size="3">
In this paper, we present the "IoT Security Dataset", a domain-specific dataset of 7,147 samples focused solely on IoT security discussions. 
We further employed multiple transformer models to automatically detect security discussions. Through rigorous investigations, 
we found that IoT security discussions are different and more complex than traditional security discussions.
</font>
</span>
</details>
<span style="color:black"><font size="3"><strong>Authors</strong>: Nibir Chandra Mandal, <strong style="color:green">G. M. Shahariar</strong>, and Md. Tanvir Rouf Shawon</font></span><br>
<span style="color:black"><font size="3"><strong>Conference:</strong><em> International Conference on Information and Communication Technology for Development</em></font> ([ICICTD 2022](https://link.springer.com/book/10.1007/978-981-19-7528-8))</span><br>
[[<span style ="color:#6E2C00"><font size="3"><strong>PDF</strong></font></span>](https://www.researchgate.net/publication/367439808_Effectiveness_of_Transformer_Models_on_IoT_Security_Detection_in_StackOverflow_Discussions)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Dataset</strong></font></span>](https://github.com/shahariar-shibli/Effectiveness-of-Transformer-Models-on-IoT-Security-Detection-in-StackOverflow-Discussions)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Presentation</strong></font></span>](https://shahariar-shibli.github.io/files/ICICTD2022/PaperID_68.pdf) \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/ICICTD2022/IoT-Security.bib)]
    

## 2022
---------
üìå [<span style="color:red">**Automatic back transliteration of Romanized Bengali (Banglish) to Bengali**</span>](https://link.springer.com/article/10.1007/s42044-022-00122-9)
<details>
<summary><font size="3">Click to read a short summary!</font></summary>
<span style="text-align:justify; color:black; display:block;"> 
<font size="3">
This paper introduces a unique pipeline that uses nine open source back transliteration tools to automatically back transliterate
 Romanized Bengali (Banglish) to Bengali.
</font>
</span>
</details>
<span style="color:black"><font size="3"><strong>Authors</strong>: <strong style="color:green">G. M. Shahariar Shibli</strong>, Md. Tanvir Rouf Shawon, Anik Hassan Nibir, Md. Zabed Miandad, and Nibir Chandra Mandal</font></span><br>
<span style="color:black"><font size="3"><strong>Journal:</strong><em> Iran Journal of Computer Science</em></font> ([Iran J Comput Sci](https://www.springer.com/journal/42044))</span><br>
[[<span style ="color:#6E2C00"><font size="3"><strong>PDF</strong></font></span>](https://shahariar-shibli.github.io/files/IRAN2022/Banglish_to_Bangla.pdf) \|  [<span style ="color:#6E2C00"><font size="3"><strong>Code & Dataset</strong></font></span>](https://github.com/shahariar-shibli/Automatic-Back-Transliteration-of-Romanized-Bengali-Banglish-to-Bengali)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/IRAN2022/Banglish_to_Bangla.bib)]

üìå [<span style="color:red">**Urgent Text Detection in Bengali Language Based on Boosting Techniques**</span>](https://link.springer.com/chapter/10.1007/978-981-19-2445-3_49)
<details>
<summary><font size="3">Click to read a short summary!</font></summary>
<span style="text-align:justify; color:black; display:block;"> 
<font size="3">
This paper presents traditional machine learning classifiers and boosting techniques to 
detect urgent texts from the posts of social media platforms.
</font>
</span>
</details>
<span style="color:black"><font size="3"><strong>Authors</strong>: Rafsan Rahman, Tamanna Nazmin, Noor Nafeur Rahman, Miyad Bhuiyan, <strong style="color:green">G. M. Shahariar</strong>, and Faisal Muhammad Shah</font></span><br>
<span style="color:black"><font size="3"><strong>Conference:</strong><em> International Conference on Fourth Industrial Revolution and Beyond</em></font> ([ICFIRB 2022](https://link.springer.com/book/10.1007/978-981-19-2445-3))</span><br>
[[<span style ="color:#6E2C00"><font size="3"><strong>PDF</strong></font></span>](https://www.researchgate.net/publication/364138051_Urgent_Text_Detection_in_Bengali_Language_Based_on_Boosting_Techniques)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/ICFIRB2022/Urgent-Text.bib)]

üìå [<span style="color:red">**Assorted, Archetypal and Annotated Two Million (3A2M) Cooking Recipes Dataset based on Active Learning**</span>](https://www.researchgate.net/publication/364384652_Assorted_Archetypal_and_Annotated_Two_Million_3A2M_Cooking_Recipes_Dataset_based_on_Active_Learning)
<details>
<summary><font size="3">Click to read a short summary!</font></summary>
<span style="text-align:justify; color:black; display:block;"> 
<font size="3">
In this study, we present a novel dataset of two million culinary recipes labeled in nine categories 
(bakery, drinks, non-veg, vegetables, fast food, cereals, meals, sides and fusion) leveraging the 
knowledge of food experts and active learning technique.
</font>
</span>
</details>
<span style="color:black"><font size="3"><strong>Authors</strong>: Nazmus Sakib, <strong style="color:green">G. M. Shahariar</strong>, Md. Mohsinul Kabir, Md. Kamrul, and Hasan Mahmud</font></span><br>
<span style="color:black"><font size="3"><strong>Conference:</strong><em> International Conference on Machine Intelligence and Emerging Technologies</em></font> ([MIET 2022](https://confmiet.org/))</span><br>
[[<span style ="color:#6E2C00"><font size="3"><strong>arXiv</strong></font></span>](https://arxiv.org/abs/2303.16778)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Dataset</strong></font></span>](https://www.kaggle.com/datasets/nazmussakibrupol/3a2m-cooking-recipe-dataset)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Presentation</strong></font></span>](https://shahariar-shibli.github.io/files/MIET2022/PaperID_462.pdf)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/MIET2022/3A2M.bib)]
 
üìå [<span style="color:red">**Can Transformer Models Effectively Detect Software Aspects in StackOverflow Discussion?**</span>](https://www.researchgate.net/publication/363859059_Can_Transformer_Models_Effectively_Detect_Software_Aspects_in_StackOverflow_Discussion)
<details>
<summary><font size="3">Click to read a short summary!</font></summary>
<span style="text-align:justify; color:black; display:block;"> 
<font size="3">
In this paper, we have used a benchmark API aspects dataset (Opiner) collected from StackOverflow posts and 
observed how Transformer models (BERT, RoBERTa, DistilBERT, and XLNet) perform in detecting software aspects 
in textual developer discussion with respect to the baseline Support Vector Machine (SVM) model.
</font>
</span>
</details>
<span style="color:black"><font size="3"><strong>Authors</strong>: Nibir Chandra Mandal, Tashreef Muhammad, and <strong style="color:green">G. M. Shahariar</strong></font></span><br>
<span style="color:black"><font size="3"><strong>Conference:</strong><em> International Conference on Machine Intelligence and Emerging Technologies</em></font> ([MIET 2022](https://confmiet.org/))</span><br>
[[<span style ="color:#6E2C00"><font size="3"><strong>arXiv</strong></font></span>](https://arxiv.org/abs/2209.12065)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Dataset</strong></font></span>](https://shahariar-shibli.github.io/files/MIET2022/UddinSOAspect.csv)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Presentation</strong></font></span>](https://shahariar-shibli.github.io/files/MIET2022/PaperID_371.pptx)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/MIET2022/Nibir-Aspect.bib)]
 
## 2021
-------
üìå [<span style="color:red">**Ben-Sarc: A Corpus for Sarcasm Detection from Bengali Social Media Comments and Its Baseline Evaluation**</span>](https://www.researchgate.net/publication/357888683_Ben-Sarc_A_Corpus_for_Sarcasm_Detection_from_Bengali_Social_Media_Comments_and_Its_Baseline_Evaluation)
<details>
<summary><font size="3">Click to read a short summary!</font></summary>
<span style="text-align:justify; color:black; display:block;"> 
<font size="3">
In this paper, we introduce a large-scale self annotated Bengali corpus for sarcasm detection (Ben-Sarc) in the 
Bengali language containing 25,636 comments and we report the comparison between the performance of traditional 
machine learning, deep learning,and transfer learning models using pre-trained models (PTMs) in terms of sarcasm 
detection.
</font>
</span>
</details>
<span style="color:black"><font size="3"><strong>Authors</strong>: Sanzana Karim Lora, <strong style="color:green">G. M. Shahariar</strong>, Tamanna Nazmin, Noor Nafeur Rahman, Rafsan Rahman, Miyad Bhuiyan, and Faisal Muhammad shah</font></span><br>
<span style="color:black"><font size="3"><strong>Journal:</strong> <span style ="color:orchid"><em>under review</em></span></font></span><br>
[[<span style ="color:#6E2C00"><font size="3"><strong>engrXiv</strong></font></span>](https://engrxiv.org/preprint/view/2102/4194)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Dataset</strong></font></span>](https://docs.google.com/spreadsheets/d/1paQG4X28R7kiV3zYN9Lwa3mJgouXZjqL/edit#gid=785602251)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/IN-REVIEW/Ben-Sarc.bib)]



## 2019
-------
üìå [<span style="color:red">**Spam Review Detection Using Deep Learning**</span>](https://ieeexplore.ieee.org/document/8936148)
<details>
<summary><font size="3">Click to read a short summary!</font></summary>
<span style="text-align:justify; color:black; display:block;"> 
<font size="3">
To detect spam reviews from both labeled and unlabeled data we applied deep learning methods like Multi-Layer Perceptron (MLP),
 Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM). We have also applied some traditional machine learning 
 classifiers such as Nave Bayes (NB), K Nearest Neighbor (KNN) and Support Vector Machine (SVM). To label the unlabeled data 
 we utilized active learning technique.
</font>
</span>
</details>
<span style="color:black"><font size="3"><strong>Authors</strong>: <strong style="color:green">G. M. Shahariar</strong>, Swapnil Biswas, Faiza Omar, Faisal Muhammad Shah, and Samiha Binte Hassan</font></span><br>
<span style="color:black"><font size="3"><strong>Conference:</strong><em> 10th Annual Information Technology, Electronics and Mobile Communication Conference</em></font> ([IEMCON 2019](https://ieee-iemcon.org/ieee-iemcon-2019-2/))</span><br>
[[<span style ="color:#6E2C00"><font size="3"><strong>PDF</strong></font></span>](https://www.researchgate.net/publication/338071063_Spam_Review_Detection_Using_Deep_Learning)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Presentation</strong></font></span>](https://shahariar-shibli.github.io/files/IEMCON2019/Spam-Final.pptx)  \|  [<span style ="color:#6E2C00"><font size="3"><strong>Citation</strong></font></span>](https://shahariar-shibli.github.io/files/IEMCON2019/Spam-Deep.bib)]
 


